{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "014f811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "os.umask(0)\n",
    "# os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "# os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "# os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "import pickle\n",
    "import sys\n",
    "from importlib import import_module\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Sampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data import ArgoTestDataset\n",
    "from torch.utils.data import Sampler, DataLoader\n",
    "from utils import Logger, load_pretrain\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f44dcf48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Import all settings for experiment.\n",
    "\n",
    "model = import_module(\"lanegcn\")\n",
    "config, _, collate_fn, net, loss, post_process, opt = model.get_model()\n",
    "\n",
    "# load pretrain model\n",
    "# ckpt_path = \"/mnt/lustre/tangxiaqiang/Code/LaneGCN/36.000.ckpt\"\n",
    "# if not os.path.isabs(ckpt_path):\n",
    "#     ckpt_path = os.path.join(config[\"save_dir\"], ckpt_path)\n",
    "# ckpt = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n",
    "\n",
    "# # load a ddp model \n",
    "# from collections import OrderedDict\n",
    "# new_state_dict = OrderedDict()  \n",
    "# for k, v in ckpt[\"state_dict\"].items():\n",
    "#     name = k[7:] # remove `module.`\n",
    "#     new_state_dict[name] = v\n",
    "# net.load_state_dict(new_state_dict,strict=True)\n",
    "\n",
    "\n",
    "ckpt_path = \"/mnt/lustre/tangxiaqiang/Code/LaneGCN/pretrain.ckpt\"\n",
    "if not os.path.isabs(ckpt_path):\n",
    "    ckpt_path = os.path.join(config[\"save_dir\"], ckpt_path)\n",
    "ckpt = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n",
    "net.load_state_dict(ckpt[\"state_dict\"],strict=True)\n",
    "\n",
    "# from collections import OrderedDict\n",
    "# new_state_dict = OrderedDict()  \n",
    "# ckpt_path = \"/mnt/lustre/tangxiaqiang/Code/LaneGCN/model.ckpt\"\n",
    "# ckpt = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n",
    "# for k, v in ckpt.items():\n",
    "#     name = k[7:] # remove `module.`\n",
    "#     new_state_dict[name] = v\n",
    "# net.load_state_dict(new_state_dict,strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7b2bbc8-fd74-4857-85cf-e82c4d90a0a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'display_iters': 400,\n",
       " 'val_iters': 1608,\n",
       " 'save_freq': 1.0,\n",
       " 'epoch': 0,\n",
       " 'horovod': True,\n",
       " 'opt': 'adam',\n",
       " 'num_epochs': 2,\n",
       " 'lr': [0.004, 0.0004],\n",
       " 'lr_epochs': [32],\n",
       " 'lr_func': <utils.StepLR at 0x7f6c784dcf90>,\n",
       " 'save_dir': '/mnt/lustre/tangxiaqiang/Code/LaneGCN/results/lanegcn',\n",
       " 'batch_size': 128,\n",
       " 'val_batch_size': 32,\n",
       " 'workers': 0,\n",
       " 'val_workers': 0,\n",
       " 'train_split': '/mnt/lustre/tangxiaqiang/Code/LaneGCN/dataset/train/data',\n",
       " 'val_split': '/mnt/lustre/tangxiaqiang/Code/LaneGCN/dataset/val/data',\n",
       " 'test_split': '/mnt/lustre/tangxiaqiang/Code/LaneGCN/dataset/test_obs/data',\n",
       " 'preprocess': True,\n",
       " 'preprocess_train': '/mnt/lustre/tangxiaqiang/Code/LaneGCN/dataset/preprocess/train_crs_dist6_angle90.p',\n",
       " 'preprocess_val': '/mnt/lustre/tangxiaqiang/Code/LaneGCN/dataset/preprocess/val_crs_dist6_angle90.p',\n",
       " 'preprocess_test': '/mnt/lustre/tangxiaqiang/Code/LaneGCN/dataset/preprocess/test_test.p',\n",
       " 'rot_aug': False,\n",
       " 'pred_range': [-100.0, 100.0, -100.0, 100.0],\n",
       " 'num_scales': 6,\n",
       " 'n_actor': 128,\n",
       " 'n_map': 128,\n",
       " 'actor2map_dist': 7.0,\n",
       " 'map2actor_dist': 6.0,\n",
       " 'actor2actor_dist': 100.0,\n",
       " 'pred_size': 30,\n",
       " 'pred_step': 1,\n",
       " 'num_preds': 30,\n",
       " 'num_mods': 6,\n",
       " 'cls_coef': 1.0,\n",
       " 'reg_coef': 1.0,\n",
       " 'mgn': 0.2,\n",
       " 'cls_th': 2.0,\n",
       " 'cls_ignore': 0.2}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6363a56-3361-49fc-b230-1babbeef6f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['preprocess']=True\n",
    "# Data loader for evaluation\n",
    "\n",
    "Dataset=_\n",
    "dataset = Dataset(config[\"val_split\"], config, train=False)\n",
    "val_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=config[\"val_batch_size\"],\n",
    "    num_workers=config[\"val_workers\"],\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "# batch=next(iter(val_loader))\n",
    "# batch\n",
    "##test dataloader\n",
    "dataset = ArgoTestDataset(\"test\", config, train=False)\n",
    "test_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=128,#config[\"val_batch_size\"],\n",
    "    num_workers=config[\"val_workers\"],\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a734dd-9d9d-452f-a8ad-c6ade43ab5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#val\n",
    "preds = {}\n",
    "gts = {}\n",
    "cities = {}\n",
    "net.cuda()\n",
    "net.eval()\n",
    "metrics = dict()\n",
    "for ii, data in tqdm(enumerate(val_loader)):\n",
    "    data = dict(data)\n",
    "    with torch.no_grad():\n",
    "        output = net(data)\n",
    "        results = [x[0:1].detach().cpu().numpy() for x in output[\"reg\"]]\n",
    "\n",
    "        loss_out = loss(output, data)\n",
    "        print(loss_out)\n",
    "        post_out = post_process(output, data)\n",
    "        post_process.append(metrics, loss_out, post_out)\n",
    "        post_process.display(metrics, 0, 0, 0)\n",
    "\n",
    "    # for i, (argo_idx, pred_traj) in enumerate(zip(data[\"argo_id\"], results)):\n",
    "    #     preds[argo_idx] = pred_traj.squeeze()\n",
    "    #     cities[argo_idx] = data[\"city\"][i]\n",
    "    #     gts[argo_idx] = data[\"gt_preds\"][i][0] if \"gt_preds\" in data else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b9f4a9-830c-49fd-a99d-ddcb1fb936b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# begin inference\n",
    "preds = {}\n",
    "gts = {}\n",
    "cities = {}\n",
    "net.cuda()\n",
    "metrics = dict()\n",
    "for ii, data in tqdm(enumerate(data_loader)):\n",
    "    data = dict(data)\n",
    "    with torch.no_grad():\n",
    "        output = net(data)\n",
    "        results = [x[0:1].detach().cpu().numpy() for x in output[\"reg\"]]\n",
    "\n",
    "\n",
    "    for i, (argo_idx, pred_traj) in enumerate(zip(data[\"argo_id\"], results)):\n",
    "        preds[argo_idx] = pred_traj.squeeze()\n",
    "        cities[argo_idx] = data[\"city\"][i]\n",
    "        gts[argo_idx] = data[\"gt_preds\"][i][0] if \"gt_preds\" in data else None\n",
    "\n",
    "# save for further visualization\n",
    "res = dict(\n",
    "    preds = preds,\n",
    "    gts = gts,\n",
    "    cities = cities,\n",
    ")\n",
    "# torch.save(res,f\"{config['save_dir']}/results.pkl\")\n",
    "\n",
    "# evaluate or submit\n",
    "if args.split == \"val\":\n",
    "    # for val set: compute metric\n",
    "    from argoverse.evaluation.eval_forecasting import (\n",
    "        compute_forecasting_metrics,\n",
    "    )\n",
    "    # Max #guesses (K): 6\n",
    "    _ = compute_forecasting_metrics(preds, gts, cities, 6, 30, 2)\n",
    "    # Max #guesses (K): 1\n",
    "    _ = compute_forecasting_metrics(preds, gts, cities, 1, 30, 2)\n",
    "else:\n",
    "    # for test set: save as h5 for submission in evaluation server\n",
    "    from argoverse.evaluation.competition_util import generate_forecasting_h5\n",
    "    generate_forecasting_h5(preds, f\"{config['save_dir']}/submit.h5\")  # this might take awhile\n",
    "    print(\"----------------finish generate---------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eca9270-092f-417c-90c9-91d32a11e63f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
